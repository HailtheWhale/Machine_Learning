{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HailtheWhale/Personal_Projects/blob/main/Image_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2DpE0bCu8Ap",
        "outputId": "4261737a-959a-4429-ba3b-723bad10406d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Raw_Randomized_Images' has been cleared. \n",
            "The old one can be found in Backup Images with it's timestamp.\n",
            "\n",
            "The folder '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Marked_Randomized_Images' has been cleared. \n",
            "The old one can be found in Backup Images with it's timestamp.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This code is meant to backup and clear out the randomized \n",
        "images generated below. \n",
        "Found in Backup_Images \n",
        "'''\n",
        "\n",
        "import os \n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "############ Moving Old Folders \n",
        "\n",
        "# Getting Folder Paths  \n",
        "raw_src_path = \"/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Raw_Randomized_Images\"\n",
        "marked_src_path = \"/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Marked_Randomized_Images\"\n",
        "backup_dst_path = \"/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Backup_Images\"\n",
        "\n",
        "# Moving Folders to Backup Folder \n",
        "shutil.move(raw_src_path, backup_dst_path)\n",
        "shutil.move(marked_src_path, backup_dst_path)\n",
        "\n",
        "############ Renaming the Moved Folders \n",
        "\n",
        "# Getting Date and time \n",
        "dt_string = datetime.now()\n",
        "dt_string = dt_string.strftime(\"%H:%M:%S %b %d %Y\")\n",
        "\n",
        "# Printing time stamp on associated folders\n",
        "# Raw\n",
        "raw_folder_name = \"/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Backup_Images/Raw_Randomized_Images\"\n",
        "raw_new_folder_name = str(dt_string) + \" \" + \"Raw_Randomized_Images\"\n",
        "raw_new_folder_name = os.path.join(backup_dst_path, raw_new_folder_name)\n",
        "os.rename(raw_folder_name, raw_new_folder_name)\n",
        "\n",
        "# Marked \n",
        "marked_folder_name = \"/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Backup_Images/Marked_Randomized_Images\"\n",
        "marked_new_folder_name = str(dt_string) + \" \" + \"Marked_Randomized_Images\"\n",
        "marked_new_folder_name = os.path.join(backup_dst_path, marked_new_folder_name)\n",
        "os.rename(marked_folder_name, marked_new_folder_name)\n",
        "\n",
        "############ Making new files to replace the old ones \n",
        "# Directory / File to be made \n",
        "raw_file_name = \"Raw_Randomized_Images\"\n",
        "marked_file_name = \"Marked_Randomized_Images\"\n",
        "\n",
        "# File path the File will be made in \n",
        "parent_folder = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images'\n",
        "\n",
        "# Combined path of new folder \n",
        "new_raw_folder = os.path.join(parent_folder, raw_file_name)\n",
        "new_random_folder = os.path.join(parent_folder, marked_file_name)\n",
        "\n",
        "# Making new folder\n",
        "os.mkdir(new_raw_folder)\n",
        "os.mkdir(new_random_folder) \n",
        "\n",
        "print(\"The folder '% s' has been cleared. \\nThe old one can be found in Backup Images with it's timestamp.\\n\" % new_raw_folder)\n",
        "print(\"The folder '% s' has been cleared. \\nThe old one can be found in Backup Images with it's timestamp.\\n\" % new_random_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EL-M-aXzkpw"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This code is meant to generate more\n",
        "randomized images for data. The randomization \n",
        "is based on seed use, and the marked randomized \n",
        "images correspond to the raw. \n",
        "'''\n",
        "\n",
        "# Data Augmentation \n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img \n",
        "import os\n",
        "\n",
        "# Initializing Datagen Parameters \n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.5,\n",
        "    fill_mode='wrap'\n",
        ")\n",
        "\n",
        "# Initializing Directory Paths \n",
        "dir_raw = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Test_Images/Raw_Test_Images' # raw irectory \n",
        "dir_marked = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Test_Images/Marked_Test_Images' #marked directory \n",
        "dir_base = [dir_raw, dir_marked]\n",
        "\n",
        "rand_img_count = 0\n",
        "dup_cnt = 2\n",
        "\n",
        "# Looping through both directories \n",
        "for dir in dir_base:\n",
        "  # Looping thru dir\n",
        "  print(f'The Directory is: {dir}') # Directory working on\n",
        "\n",
        "  for imagename in os.listdir(dir):\n",
        "    print(f'\\nThe image is {imagename}')\n",
        "    img_path = os.path.join(dir, imagename)\n",
        "\n",
        "    img = load_img(img_path) # Loading image\n",
        "    x = img_to_array(img) # Converting image to numpy array \n",
        "    x = x.reshape((1,) + x.shape) # reshaping image \n",
        "    # Dimensions of image. (1,480,640,3) for all. 480,640 = dimensions.\n",
        "    # 3 = RGB. 1 = img batch size. \n",
        "    print(f'The shape is {x.shape}') \n",
        "\n",
        "  ## Removing .png ending from image name \n",
        "    modified_image_prefix = list(imagename) # Casting string to list \n",
        "    for num in range(4):\n",
        "      modified_image_prefix.pop() # removing last 4 letters \n",
        "    joined_prefix = ''.join(modified_image_prefix) # rejoining\n",
        "\n",
        "  ## Setting Image Save Directories \n",
        "    if dir == dir_raw:\n",
        "      save_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Raw_Randomized_Images'\n",
        "    else:\n",
        "      save_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Marked_Randomized_Images'\n",
        "\n",
        "  ## Applying randomizations \n",
        "    i = 0 # initializing counter. DETERMINES randomized count for each image in filepath\n",
        "    for batch in datagen.flow(\n",
        "          x,\n",
        "          batch_size=1,\n",
        "          seed=1, \n",
        "          save_to_dir= save_path,\n",
        "          save_prefix = joined_prefix,\n",
        "          save_format = 'jpeg'):\n",
        "      i += 1 \n",
        "      print(f\"Generated {i} image(s).\")\n",
        "      rand_img_count = rand_img_count + 1 # updating image counter\n",
        "      if i >= dup_cnt:\n",
        "        break\n",
        "  \n",
        "  # Spacing Image info\n",
        "  print('\\n########')\n",
        "\n",
        "print(f'\\n{rand_img_count/2} raw images generated.')\n",
        "print(f'{rand_img_count/2} marked images generated.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V37JwFqp_zzz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This code is meant to test \n",
        "marked data extraction, and\n",
        "determine which channel from the \n",
        "RGB image would give the marked data\n",
        "index based on an easily seen threshold value.\n",
        "Raw data is also extracted for comparison. \n",
        "'''\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "img_index = 3 # Selects the img to test \n",
        "\n",
        "raw_rand_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Raw_Randomized_Images'\n",
        "marked_rand_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Marked_Randomized_Images'\n",
        "\n",
        "# Selecting samples from folder\n",
        "raw_image = os.listdir(raw_rand_dir)\n",
        "raw_image = raw_image[img_index]\n",
        "print(f'The raw image is {raw_image}')\n",
        "\n",
        "marked_image = os.listdir(marked_rand_dir)\n",
        "marked_image = marked_image[img_index]\n",
        "print(f'The marked image is {marked_image}')\n",
        "\n",
        "print(f'\\nThe selected random image index is {img_index}')\n",
        "\n",
        "# Making sample loads ready\n",
        "raw_img_path = os.path.join(raw_rand_dir, raw_image)\n",
        "marked_img_path = os.path.join(marked_rand_dir, marked_image)\n",
        "\n",
        "######### Marked Image Test \n",
        "\n",
        "# Getting RGB pixel values for marked image.\n",
        "# Tuple position correspond to \n",
        "# R, G, and B channels respectively\n",
        "marked_img = Image.open(marked_img_path, 'r')\n",
        "marked_pix_val = list(marked_img.getdata())\n",
        "print(f'\\nThe dimensions for the marked tuple are {marked_pix_val[0]}') # For demonstration\n",
        "\n",
        "# Creating empty lists. If the value is above the given \n",
        "# threshold, the list will be appended with that tuple.\n",
        "# The list that has the greatest length will be used \n",
        "# to extract the marked coordinates\n",
        "\n",
        "list_R = []\n",
        "list_G = []\n",
        "list_B = []\n",
        "threshold = 254\n",
        "\n",
        "for R,G,B in marked_pix_val:\n",
        "  if R >= threshold:\n",
        "    list_R.append(R)\n",
        "  if G >= threshold:\n",
        "    list_G.append(G)\n",
        "  if B >= threshold:\n",
        "    list_B.append(B)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "print('\\nMarked Channel Test')\n",
        "print('Values from the channel threshold test are:')\n",
        "print(f'Red: {len(list_R)}')\n",
        "print(f'Green: {len(list_G)}')\n",
        "print(f'Blue: {len(list_B)}')\n",
        "print(f'The threshold value was: {threshold}')\n",
        "\n",
        "########## Raw Image Test\n",
        "\n",
        "# Getting RGB pixel values for Raw image.\n",
        "# Tuple position correspond to \n",
        "# R, G, and B channels respectively\n",
        "raw_img = Image.open(raw_img_path, 'r')\n",
        "raw_pix_val = list(raw_img.getdata())\n",
        "print(f'\\nThe dimensions for the raw tuple are {raw_pix_val[0]}') # For demonstration\n",
        "\n",
        "# Creating empty lists. If the value is above the given \n",
        "# threshold, the list will be appended with that value.\n",
        "# The list that has the greatest length will be used \n",
        "# to extract the marked coordinates.\n",
        "\n",
        "list_R = []\n",
        "list_G = []\n",
        "list_B = []\n",
        "threshold = 254\n",
        "\n",
        "for R,G,B in raw_pix_val:\n",
        "  if R >= threshold:\n",
        "    list_R.append(R)\n",
        "  if G >= threshold:\n",
        "    list_G.append(G)\n",
        "  if B >= threshold:\n",
        "    list_B.append(B)\n",
        "  else:\n",
        "    pass\n",
        "print('\\nRaw Channel Test')\n",
        "print('Values from the channel threshold test are:')\n",
        "print(f'Red: {len(list_R)}')\n",
        "print(f'Green: {len(list_G)}')\n",
        "print(f'Blue: {len(list_B)}')\n",
        "print(f'The threshold value was: {threshold}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code is just to find image dimensions \n",
        "'''\n",
        "from keras.preprocessing.image import img_to_array, load_img \n",
        "\n",
        "print(\"Pixels in Image:\", len(marked_pix_val))\n",
        "img = load_img(raw_img_path) # Loading image\n",
        "x = img_to_array(img) # Converting image to numpy array \n",
        "print(\"Image Shape:\", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBGHFLWY86BJ",
        "outputId": "3b66c289-c06b-4f03-83e0-99398ce6ab7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixels in Image: 307200\n",
            "Image Shape: (480, 640, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code is meant to backup and clear out \n",
        "the Image data .csv files made below.\n",
        "Found in the ML_Data_Backups folder.\n",
        "'''\n",
        "\n",
        "import os \n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "############ Moving Old Folders \n",
        "\n",
        "# Getting Folder Paths  \n",
        "csv_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Image_Data'\n",
        "backup_dst_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/ML_Data_Backups'\n",
        "\n",
        "# Moving Folder to Backup Folder \n",
        "shutil.move(csv_path, backup_dst_path)\n",
        "\n",
        "############ Renaming the Moved Folders \n",
        "\n",
        "# Getting Date and time \n",
        "dt_string = datetime.now()\n",
        "dt_string = dt_string.strftime(\"%H:%M:%S %b %d %Y\")\n",
        "\n",
        "# Printing time stamp on folder\n",
        "csv_folder_name = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/ML_Data_Backups/Image_Data'\n",
        "new_csv_folder_name = str(dt_string) + \" \" + \"Image_Data\"\n",
        "new_csv_folder_name = os.path.join(backup_dst_path, new_csv_folder_name)\n",
        "os.rename(csv_folder_name, new_csv_folder_name)\n",
        "\n",
        "#####################################\n",
        "# Making new folder to replace the old one\n",
        "#####################################\n",
        "\n",
        "# Directory \n",
        "csv_folder_name = \"Image_Data\"\n",
        "\n",
        "# File path the File will be made in \n",
        "parent_folder = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data'\n",
        "\n",
        "# Combined path of new folder \n",
        "new_csv_folder = os.path.join(parent_folder, csv_folder_name)\n",
        "\n",
        "# Making new folder\n",
        "os.mkdir(new_csv_folder)\n",
        "\n",
        "print(\"The folder '% s' has been cleared. \\nThe old one can be found in ML_Data_Backups with it's timestamp.\\n\" % new_csv_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "847avkaaH_cK",
        "outputId": "a3d1c526-af35-42b2-de5f-a6e34aa23544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Image_Data' has been cleared. \n",
            "The old one can be found in ML_Data_Backups with it's timestamp.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBPwopOLq5F2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This code is meant to generate \n",
        "the needed data lists for the \n",
        ".csv ML individual test files, and write the \n",
        ".csv files. Fills the Image_Data Folder. \n",
        "'''\n",
        "# For data list creation \n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# For .csv file writing \n",
        "import csv \n",
        "\n",
        "# Directories \n",
        "raw_rand_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Raw_Randomized_Images'\n",
        "marked_rand_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Marked_Randomized_Images'\n",
        "csv_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Image_Data'\n",
        "\n",
        "image_cnt = 0\n",
        "\n",
        "# Randomized img index selection \n",
        "# Loops thru all images \n",
        "for image in range(0, len(os.listdir(raw_rand_dir))):\n",
        "\n",
        "  image_cnt += 1\n",
        "  print(f'\\nThis is image {image_cnt}')\n",
        "\n",
        "  print('The image names are as follows:')\n",
        "\n",
        "  # Selecting samples from folder\n",
        "  raw_image_list = os.listdir(raw_rand_dir)\n",
        "  raw_image = raw_image_list[image]\n",
        "  print(f'     The raw image is {raw_image}')\n",
        "\n",
        "  marked_image_list = os.listdir(marked_rand_dir)\n",
        "  marked_image = marked_image_list[image]\n",
        "  print(f'     The marked image is {marked_image}')\n",
        "\n",
        "  # Making sample loads ready\n",
        "  raw_img_path = os.path.join(raw_rand_dir, raw_image)\n",
        "  marked_img_path = os.path.join(marked_rand_dir, marked_image)\n",
        "\n",
        "  ##################\n",
        "  # Exactracting needed values from images\n",
        "  ##################\n",
        "\n",
        "  # Converting marked image into flattened \n",
        "  # list of RGB values.\n",
        "  marked_img = Image.open(marked_img_path, 'r')\n",
        "  marked_pix_val = list(marked_img.getdata())\n",
        "\n",
        "  # Converting marked image into flattened \n",
        "  # list of RGB values.\n",
        "  raw_img = Image.open(raw_img_path, 'r')\n",
        "  raw_pix_val = list(raw_img.getdata())\n",
        "\n",
        "  ###################\n",
        "  # Forming Data List \n",
        "  ###################\n",
        "\n",
        "  # Forming Blank Data list for .csv file \n",
        "  data_list = [[0,0,0,0,0,0]]\n",
        "  for index in range(1,len(marked_pix_val)):\n",
        "    data_list.append([0,0,0,0,0,0])\n",
        "\n",
        "  # Updating Flattened Index Values in data_list\n",
        "  # Placing X and Y Coordinates\n",
        "  j = -1\n",
        "  index = 0\n",
        "  for Y in range(0,int(len(data_list)/640)):\n",
        "    j += 1\n",
        "    i = -1\n",
        "    for X in range(0,int(len(data_list)/480)):\n",
        "      i += 1\n",
        "      index = i + j*640\n",
        "      data_list[index][0] = X\n",
        "      data_list[index][1] = Y\n",
        "\n",
        "  #####################\n",
        "  # Raw Data RGB Extraction and Application\n",
        "  #####################\n",
        "\n",
        "  # Updating R,G,B values in data_list \n",
        "  i = -1\n",
        "  for index in raw_pix_val:\n",
        "    i += 1\n",
        "    data_list[i][2] = raw_pix_val[i][0]\n",
        "    data_list[i][3] = raw_pix_val[i][1]\n",
        "    data_list[i][4] = raw_pix_val[i][2]\n",
        "\n",
        "  ######### Label Extraction and Application via Marked Images \n",
        "\n",
        "  # Updating labels in data_list\n",
        "  i = -1\n",
        "  for R,G,B in marked_pix_val:\n",
        "    i+=1\n",
        "    if R >= 254:\n",
        "      data_list[i][5] = 1 # True Defect\n",
        "    else:\n",
        "      data_list[i][5] = 0 # False Defect \n",
        "\n",
        "  # UI Display\n",
        "  print(f'The data_list is:\\n     {len(data_list)} spaces long') # length check \n",
        "  check = len(data_list) == len(raw_pix_val)\n",
        "  print(f'Is the length of the data = to the no. of pixels? \\n   {check}')\n",
        "  print(\"Here is what the data lists look like:\\n   \", data_list[0:3]) # List check \n",
        "\n",
        "  #########################################################\n",
        "  # Writing Data Files \n",
        "  #########################################################\n",
        "\n",
        "  header = ['X', 'Y', 'R', 'G', \"B\", \"label\"]\n",
        "  data = data_list\n",
        "\n",
        "  # Getting File base name \n",
        "  ## Removing .png ending from image name \n",
        "  image_name = list(raw_image) # Casting string to list \n",
        "  image_name_list = [] # making blank list \n",
        "\n",
        "  image_name_list.append(image_name[4:-5]) # pulling desired letters \n",
        "  base_name = ''.join(image_name_list[0]) # making word \n",
        "  base_name = base_name + \".csv\"\n",
        "\n",
        "  # Creating File Name\n",
        "  image_csv = os.path.join(csv_dir, base_name)\n",
        "\n",
        "  # Opening file in write mode \n",
        "  f = open(image_csv, 'w')\n",
        "\n",
        "  writer = csv.writer(f)\n",
        "\n",
        "  # Writing Header \n",
        "  writer.writerow(header)\n",
        "\n",
        "  # Writing the Data Table \n",
        "  writer.writerows(data)\n",
        "\n",
        "  # Notification \n",
        "  print(\".csv file written\")\n",
        "\n",
        "  f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code is meant to shuffle the previously made \n",
        "rows in each .csv file to simulate image pixel\n",
        "kernals. This will allow the use of \"kernals\"\n",
        "in a sequential Nueral Network based on batch size\n",
        "which corresponds to the pixel count in each \"kernal\"\n",
        "'''"
      ],
      "metadata": {
        "id": "AFtDshZFTScS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code meant to backup the Training data \n",
        "set made below. Found in ML_Data_Backups. \n",
        "'''\n",
        "'''\n",
        "This code is meant to backup and clear out \n",
        "the Image data .csv files made below.\n",
        "Found in the ML_Data_Backups folder.\n",
        "'''\n",
        "\n",
        "import os \n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "############ Moving Old Folders \n",
        "\n",
        "# Getting Folder Paths  \n",
        "csv_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Train_Data'\n",
        "backup_dst_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/ML_Data_Backups'\n",
        "\n",
        "# Moving Folder to Backup Folder \n",
        "shutil.move(csv_path, backup_dst_path)\n",
        "\n",
        "############ Renaming the Moved Folders \n",
        "\n",
        "# Getting Date and time \n",
        "dt_string = datetime.now()\n",
        "dt_string = dt_string.strftime(\"%H:%M:%S %b %d %Y\")\n",
        "\n",
        "# Printing time stamp on folder\n",
        "csv_folder_name = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/ML_Data_Backups/Train_Data'\n",
        "new_csv_folder_name = str(dt_string) + \" \" + \"Train_Data\"\n",
        "new_csv_folder_name = os.path.join(backup_dst_path, new_csv_folder_name)\n",
        "os.rename(csv_folder_name, new_csv_folder_name)\n",
        "\n",
        "#####################################\n",
        "# Making new folder to replace the old one\n",
        "#####################################\n",
        "\n",
        "# Directory \n",
        "csv_folder_name = \"Train_Data\"\n",
        "\n",
        "# File path the File will be made in \n",
        "parent_folder = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data'\n",
        "\n",
        "# Combined path of new folder \n",
        "new_csv_folder = os.path.join(parent_folder, csv_folder_name)\n",
        "\n",
        "# Making new folder\n",
        "os.mkdir(new_csv_folder)\n",
        "\n",
        "print(\"The folder '% s' has been cleared. \\nThe old one can be found in ML_Data_Backups with it's timestamp.\\n\" % new_csv_folder)"
      ],
      "metadata": {
        "id": "nvNsN-UFQO7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyO-_pQ-gIPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe1f860-7527-4b68-a774-587a632802fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".csv file copied. The test data can be found in the Test_Data folder.\n"
          ]
        }
      ],
      "source": [
        "''' \n",
        "Code meant to concatenate .csv files \n",
        "to create training data set. \n",
        "Files found in the Train_Data Folder.\n",
        "Files is impossible to preview and will \n",
        "cutoff data in excel due to length. \n",
        "'''\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# .csv File directory\n",
        "csv_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Image_Data'\n",
        "\n",
        "# Initializing variables\n",
        "csv_list = os.listdir(csv_dir)\n",
        "pixel_list = []\n",
        "img_index = 0\n",
        "\n",
        "# .csv header\n",
        "header = ['X', 'Y', 'R', 'G', \"B\", \"label\"]\n",
        "\n",
        "########################################################\n",
        "# Creating Training Data List \n",
        "########################################################\n",
        "\n",
        "# Looping thru 70% of data \n",
        "split_percent = 0.70\n",
        "split = split_percent*len(os.listdir(csv_dir))\n",
        "test_len = len(os.listdir(csv_dir)) - int(split)\n",
        "\n",
        "for data in range(0, int(split)):\n",
        "\n",
        "  # Opening the .csv file\n",
        "  csv_file_path = os.path.join(csv_dir, csv_list[data]) \n",
        "  df = pd.read_csv(csv_file_path, header = 0)\n",
        "\n",
        "  i = 0 # initializing pixel counter\n",
        "\n",
        "  # Copying pixel value data \n",
        "  for row in range(0, len(df)):\n",
        "    pixel = [0,0,0,0,0,0]\n",
        "    j = -1 # initializing header index counter\n",
        "\n",
        "    for pix_val in range(0,len(header)):\n",
        "      j += 1\n",
        "      pixel[j] = df.loc[i, header[j]]\n",
        "\n",
        "    # Appending to main pixel data list \n",
        "    pixel_list.append(pixel)\n",
        "    i += 1\n",
        "\n",
        "  print(len(pixel_list))\n",
        "\n",
        "#########################################################\n",
        "# Writing Training Data to Training File\n",
        "#########################################################\n",
        "\n",
        "# Test Data Directory \n",
        "train_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Train_Data'\n",
        "\n",
        "# File Name\n",
        "train_name = \"train.csv\"\n",
        "\n",
        "# Creating File Name\n",
        "train_csv = os.path.join(train_dir, train_name)\n",
        "\n",
        "# Opening file in write mode \n",
        "f = open(train_csv, 'w')\n",
        "\n",
        "writer = csv.writer(f)\n",
        "\n",
        "# Writing Header \n",
        "writer.writerow(header)\n",
        "\n",
        "# Writing the Data Table \n",
        "writer.writerows(pixel_list)\n",
        "\n",
        "# Notification \n",
        "print(\".csv file copied. The test data can be found in the Test_Data folder.\")\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code is meant to check the dimensions of the \n",
        "training data set and compare with the values beneath epoch\n",
        "'''\n",
        "\n",
        "# Training Data Path\n",
        "train_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Train_Data/train.csv'\n",
        "\n",
        "# Reading the .csv file \n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "# Training Data dimensions \n",
        "print(len(train_df))\n",
        "\n",
        "# Image Dimensions \n",
        "column_count = 640\n",
        "row_count = 480\n",
        "\n",
        "# Backing out the number of images \n",
        "no_rows = len(train_df)/column_count\n",
        "print(\"The number of rows in the train data is:\", no_rows)\n",
        "image_count = no_rows/row_count\n",
        "print(\"The number of images is:\", image_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4gWaS2S5YUo",
        "outputId": "586df81d-dbe2-4ea8-eb0b-1a158b7f1cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4608000\n",
            "The number of rows in the train data is: 7200.0\n",
            "The number of images is: 15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Training Data Path\n",
        "train_path = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Train_Data/train.csv'\n",
        "\n",
        "# Reading the .csv file \n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "\n",
        "# Neural Network Layers \n",
        "model = keras.Sequential([\n",
        "\tkeras.layers.Dense(256, input_shape=(5,), activation='relu'),\n",
        "\tkeras.layers.Dropout(0.4),\n",
        "\tkeras.layers.Dense(128, activation='relu'),\n",
        "\tkeras.layers.Dropout(0.4),\n",
        "\tkeras.layers.Dense(128, activation='relu'),\n",
        "\tkeras.layers.Dense(2, activation='sigmoid')])\n",
        "\n",
        "# Nerual Network Compiler \n",
        "model.compile(optimizer='adam', \n",
        "\t          loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "\t          metrics=['accuracy'])\n",
        "\n",
        "# Stacking the X,Y, and RGB columns b/c \n",
        "# presumably they're codependent \n",
        "x = np.column_stack((train_df.X.values, train_df.Y.values, train_df.R.values, train_df.G.values, train_df.B.values))\n",
        "\n",
        "# Batch size = PIXEL COUNT\n",
        "model.fit(x, train_df.label.values, batch_size=640, epochs=5)"
      ],
      "metadata": {
        "id": "Hx88vL22CaPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95019c99-bbfe-465b-82e0-3d649fc22e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "7200/7200 [==============================] - 30s 4ms/step - loss: 0.2779 - accuracy: 0.9317\n",
            "Epoch 2/5\n",
            "7200/7200 [==============================] - 29s 4ms/step - loss: 0.2212 - accuracy: 0.9334\n",
            "Epoch 3/5\n",
            "7200/7200 [==============================] - 29s 4ms/step - loss: 0.2156 - accuracy: 0.9339\n",
            "Epoch 4/5\n",
            "7200/7200 [==============================] - 30s 4ms/step - loss: 0.2134 - accuracy: 0.9341\n",
            "Epoch 5/5\n",
            "7200/7200 [==============================] - 29s 4ms/step - loss: 0.2133 - accuracy: 0.9338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62c02b51d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Code meant to TEST Neural Network \n",
        "'''\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# .csv File Directory \n",
        "csv_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/ML_Data/Image_Data'\n",
        "\n",
        "# Setting split \n",
        "split_percent = 0.70\n",
        "split = split_percent*len(os.listdir(csv_dir))\n",
        "\n",
        "# Test length is leftover files.\n",
        "test_len = (len(os.listdir(csv_dir)) - int(split))\n",
        "\n",
        "# Initializing variables\n",
        "csv_list = os.listdir(csv_dir)\n",
        "\n",
        "# Index to start pulling .csv data from the back \n",
        "i = -1\n",
        "eval_num = 1\n",
        "\n",
        "# Looping thru test samples to test each one \n",
        "for data in range(0, test_len):\n",
        "  \n",
        "  csv_file_path = os.path.join(csv_dir, csv_list[i]) \n",
        "  test_df = pd.read_csv(csv_file_path)\n",
        "  i -= 1\n",
        "\n",
        "  # Stacking the X,Y, and RGB columns b/c \n",
        "  # presumably they're codependent \n",
        "  test_x = np.column_stack((test_df.X.values, test_df.Y.values, test_df.R.values, test_df.G.values, test_df.B.values))\n",
        "  \n",
        "  print(\"This is test #:\", eval_num)\n",
        "  print(\"The image is:\", csv_list[i])\n",
        "  eval_num += 1\n",
        "\n",
        "  # Running Test \n",
        "  model.evaluate(test_x, test_df.label.values)\n",
        "\n",
        "print(\"Tests Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HapyvhHY6TF7",
        "outputId": "197ef114-4c31-404b-9d86-1086413b9fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is test #: 1\n",
            "The image is: test_7_0_3462.csv\n",
            "9600/9600 [==============================] - 28s 3ms/step - loss: 0.0547 - accuracy: 0.9987\n",
            "This is test #: 2\n",
            "The image is: test_6_0_2778.csv\n",
            "9600/9600 [==============================] - 27s 3ms/step - loss: 0.0444 - accuracy: 0.9988\n",
            "This is test #: 3\n",
            "The image is: test_6_0_3462.csv\n",
            "9600/9600 [==============================] - 28s 3ms/step - loss: 0.7122 - accuracy: 0.8139\n",
            "This is test #: 4\n",
            "The image is: test_5_0_2778.csv\n",
            "9600/9600 [==============================] - 27s 3ms/step - loss: 0.6856 - accuracy: 0.7943\n",
            "This is test #: 5\n",
            "The image is: test_5_0_3462.csv\n",
            "9600/9600 [==============================] - 27s 3ms/step - loss: 0.4980 - accuracy: 0.8559\n",
            "This is test #: 6\n",
            "The image is: test_4_0_2778.csv\n",
            "9600/9600 [==============================] - 27s 3ms/step - loss: 0.5519 - accuracy: 0.8316\n",
            "This is test #: 7\n",
            "The image is: test_4_0_3462.csv\n",
            "9600/9600 [==============================] - 27s 3ms/step - loss: 0.1062 - accuracy: 0.9760\n",
            "Tests Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fs00m6OSMqt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code is meant to test the conversion\n",
        "from an image to an array back to an image\n",
        "'''\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img \n",
        "\n",
        "img_index = 3 # Selects the img to test \n",
        "\n",
        "raw_rand_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Raw_Randomized_Images'\n",
        "marked_rand_dir = '/content/drive/MyDrive/Glass_Fibre_CV_ML/Randomized_Images/Marked_Randomized_Images'\n",
        "\n",
        "# Selecting samples from folder\n",
        "raw_image = os.listdir(raw_rand_dir)\n",
        "raw_image = raw_image[img_index]\n",
        "print(f'The raw image is {raw_image}')\n",
        "\n",
        "marked_image = os.listdir(marked_rand_dir)\n",
        "marked_image = marked_image[img_index]\n",
        "print(f'The marked image is {marked_image}')\n",
        "\n",
        "print(f'\\nThe selected random image index is {img_index}')\n",
        "\n",
        "# Making sample loads ready\n",
        "raw_img_path = os.path.join(raw_rand_dir, raw_image)\n",
        "marked_img_path = os.path.join(marked_rand_dir, marked_image)\n",
        "\n",
        "######### Marked Image Test \n",
        "\n",
        "# Getting RGB pixel values for marked image.\n",
        "# Tuple position correspond to \n",
        "# R, G, and B channels respectively\n",
        "marked_img = Image.open(marked_img_path, 'r')\n",
        "marked_pix_val = list(marked_img.getdata())\n",
        "print(f'\\nThe dimensions for the marked tuple are {marked_pix_val[0:5]}') # For demonstration\n",
        "\n",
        "array = np.array(marked_pix_val)\n",
        "array = np.reshape(array, (480, 640, 3))\n",
        "image = array_to_img(array)\n",
        "image.save(\"test.jpeg\")\n",
        "Image.open(\"test.jpeg\")"
      ],
      "metadata": {
        "id": "JxX0S47d1PLN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Image_Augmentation.ipynb",
      "provenance": [],
      "mount_file_id": "1rNgsJ7tJt9HruFBBcTkIic8KB8HyLlbw",
      "authorship_tag": "ABX9TyOVJ5JlHPonfMh1BFXMqSMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}